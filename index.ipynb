{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dd5988",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Kubernetes Cluster Monitor with Graphing - For JupyterHub Stress Testing\n",
    "Monitors CPU and memory usage and generates before/during/after graphs\n",
    "\"\"\"\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from collections import defaultdict\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "REFRESH_INTERVAL = 5  # seconds between updates\n",
    "NAMESPACE = \"default\"  # Change to your JupyterHub namespace (e.g., \"jupyterhub\")\n",
    "SHOW_ALL_NAMESPACES = True  # Set to False to only show NAMESPACE above\n",
    "OUTPUT_FILE = \"k8s_stress_test_report.png\"  # Graph output filename\n",
    "\n",
    "# Data storage\n",
    "node_history = defaultdict(lambda: {'timestamps': [], 'cpu': [], 'memory': []})\n",
    "pod_history = defaultdict(lambda: {'timestamps': [], 'cpu': [], 'memory': []})\n",
    "cluster_totals = {'timestamps': [], 'cpu': [], 'memory': [], 'pod_count': []}\n",
    "\n",
    "def run_kubectl(cmd):\n",
    "    \"\"\"Run a kubectl command and return the output\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            cmd.split(),\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "        return result.stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running kubectl: {e}\")\n",
    "        return None\n",
    "\n",
    "def parse_resource(value):\n",
    "    \"\"\"Parse Kubernetes resource values (e.g., '100m', '1Gi', '500Mi')\"\"\"\n",
    "    if not value or value == '<unknown>':\n",
    "        return 0\n",
    "    \n",
    "    value = value.strip()\n",
    "    \n",
    "    # Handle CPU (millicores)\n",
    "    if value.endswith('m'):\n",
    "        return float(value[:-1]) / 1000  # Convert millicores to cores\n",
    "    \n",
    "    # Handle memory\n",
    "    if value.endswith('Ki'):\n",
    "        return float(value[:-2]) / 1024 / 1024  # Convert to GB\n",
    "    elif value.endswith('Mi'):\n",
    "        return float(value[:-2]) / 1024  # Convert to GB\n",
    "    elif value.endswith('Gi'):\n",
    "        return float(value[:-2])\n",
    "    elif value.endswith('Ti'):\n",
    "        return float(value[:-2]) * 1024\n",
    "    \n",
    "    # Assume it's already in base unit\n",
    "    try:\n",
    "        return float(value)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def get_node_metrics():\n",
    "    \"\"\"Get CPU and memory metrics for all nodes\"\"\"\n",
    "    output = run_kubectl(\"kubectl top nodes --no-headers\")\n",
    "    if not output:\n",
    "        return []\n",
    "    \n",
    "    nodes = []\n",
    "    for line in output.strip().split('\\n'):\n",
    "        if not line:\n",
    "            continue\n",
    "        parts = line.split()\n",
    "        if len(parts) >= 5:\n",
    "            nodes.append({\n",
    "                'name': parts[0],\n",
    "                'cpu_cores': parse_resource(parts[1]),\n",
    "                'cpu_percent': parts[2],\n",
    "                'memory_gb': parse_resource(parts[3]),\n",
    "                'memory_percent': parts[4]\n",
    "            })\n",
    "    return nodes\n",
    "\n",
    "def get_pod_metrics(namespace=None):\n",
    "    \"\"\"Get CPU and memory metrics for pods\"\"\"\n",
    "    if namespace:\n",
    "        cmd = f\"kubectl top pods -n {namespace} --no-headers\"\n",
    "    else:\n",
    "        cmd = \"kubectl top pods --all-namespaces --no-headers\"\n",
    "    \n",
    "    output = run_kubectl(cmd)\n",
    "    if not output:\n",
    "        return []\n",
    "    \n",
    "    pods = []\n",
    "    for line in output.strip().split('\\n'):\n",
    "        if not line:\n",
    "            continue\n",
    "        parts = line.split()\n",
    "        \n",
    "        if namespace:\n",
    "            if len(parts) >= 3:\n",
    "                pods.append({\n",
    "                    'namespace': namespace,\n",
    "                    'name': parts[0],\n",
    "                    'cpu_cores': parse_resource(parts[1]),\n",
    "                    'memory_gb': parse_resource(parts[2])\n",
    "                })\n",
    "        else:\n",
    "            if len(parts) >= 4:\n",
    "                pods.append({\n",
    "                    'namespace': parts[0],\n",
    "                    'name': parts[1],\n",
    "                    'cpu_cores': parse_resource(parts[2]),\n",
    "                    'memory_gb': parse_resource(parts[3])\n",
    "                })\n",
    "    return pods\n",
    "\n",
    "def record_metrics(timestamp, nodes, pods):\n",
    "    \"\"\"Record metrics to history for graphing\"\"\"\n",
    "    # Record node metrics\n",
    "    for node in nodes:\n",
    "        node_history[node['name']]['timestamps'].append(timestamp)\n",
    "        node_history[node['name']]['cpu'].append(node['cpu_cores'])\n",
    "        node_history[node['name']]['memory'].append(node['memory_gb'])\n",
    "    \n",
    "    # Record pod metrics (aggregate by namespace)\n",
    "    namespace_metrics = defaultdict(lambda: {'cpu': 0, 'memory': 0})\n",
    "    for pod in pods:\n",
    "        namespace_metrics[pod['namespace']]['cpu'] += pod['cpu_cores']\n",
    "        namespace_metrics[pod['namespace']]['memory'] += pod['memory_gb']\n",
    "    \n",
    "    for ns, metrics in namespace_metrics.items():\n",
    "        pod_history[ns]['timestamps'].append(timestamp)\n",
    "        pod_history[ns]['cpu'].append(metrics['cpu'])\n",
    "        pod_history[ns]['memory'].append(metrics['memory'])\n",
    "    \n",
    "    # Record cluster totals\n",
    "    total_cpu = sum(n['cpu_cores'] for n in nodes)\n",
    "    total_memory = sum(n['memory_gb'] for n in nodes)\n",
    "    cluster_totals['timestamps'].append(timestamp)\n",
    "    cluster_totals['cpu'].append(total_cpu)\n",
    "    cluster_totals['memory'].append(total_memory)\n",
    "    cluster_totals['pod_count'].append(len(pods))\n",
    "\n",
    "def generate_graphs():\n",
    "    \"\"\"Generate comprehensive graphs of the stress test\"\"\"\n",
    "    if not cluster_totals['timestamps']:\n",
    "        print(\"No data collected for graphing\")\n",
    "        return\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    # Title with test duration\n",
    "    start_time = cluster_totals['timestamps'][0]\n",
    "    end_time = cluster_totals['timestamps'][-1]\n",
    "    duration = (end_time - start_time).total_seconds() / 60\n",
    "    fig.suptitle(f'Kubernetes Cluster Stress Test Report\\n'\n",
    "                 f'Duration: {duration:.1f} minutes | '\n",
    "                 f'Start: {start_time.strftime(\"%H:%M:%S\")} | '\n",
    "                 f'End: {end_time.strftime(\"%H:%M:%S\")}',\n",
    "                 fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Cluster Total CPU Usage\n",
    "    ax1 = plt.subplot(3, 2, 1)\n",
    "    ax1.plot(cluster_totals['timestamps'], cluster_totals['cpu'], \n",
    "             linewidth=2, color='#2E86AB', marker='o', markersize=3)\n",
    "    ax1.fill_between(cluster_totals['timestamps'], cluster_totals['cpu'], \n",
    "                      alpha=0.3, color='#2E86AB')\n",
    "    ax1.set_ylabel('CPU Cores', fontsize=11, fontweight='bold')\n",
    "    ax1.set_title('Total Cluster CPU Usage', fontsize=12, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    # Add statistics\n",
    "    max_cpu = max(cluster_totals['cpu'])\n",
    "    min_cpu = min(cluster_totals['cpu'])\n",
    "    avg_cpu = sum(cluster_totals['cpu']) / len(cluster_totals['cpu'])\n",
    "    ax1.axhline(y=avg_cpu, color='red', linestyle='--', alpha=0.7, label=f'Avg: {avg_cpu:.2f}')\n",
    "    ax1.legend(loc='upper left', fontsize=9)\n",
    "    ax1.text(0.02, 0.98, f'Max: {max_cpu:.2f}\\nMin: {min_cpu:.2f}',\n",
    "             transform=ax1.transAxes, verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),\n",
    "             fontsize=9)\n",
    "    \n",
    "    # 2. Cluster Total Memory Usage\n",
    "    ax2 = plt.subplot(3, 2, 2)\n",
    "    ax2.plot(cluster_totals['timestamps'], cluster_totals['memory'], \n",
    "             linewidth=2, color='#A23B72', marker='o', markersize=3)\n",
    "    ax2.fill_between(cluster_totals['timestamps'], cluster_totals['memory'], \n",
    "                      alpha=0.3, color='#A23B72')\n",
    "    ax2.set_ylabel('Memory (GB)', fontsize=11, fontweight='bold')\n",
    "    ax2.set_title('Total Cluster Memory Usage', fontsize=12, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    # Add statistics\n",
    "    max_mem = max(cluster_totals['memory'])\n",
    "    min_mem = min(cluster_totals['memory'])\n",
    "    avg_mem = sum(cluster_totals['memory']) / len(cluster_totals['memory'])\n",
    "    ax2.axhline(y=avg_mem, color='red', linestyle='--', alpha=0.7, label=f'Avg: {avg_mem:.2f}')\n",
    "    ax2.legend(loc='upper left', fontsize=9)\n",
    "    ax2.text(0.02, 0.98, f'Max: {max_mem:.2f}\\nMin: {min_mem:.2f}',\n",
    "             transform=ax2.transAxes, verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),\n",
    "             fontsize=9)\n",
    "    \n",
    "    # 3. Per-Node CPU Usage\n",
    "    ax3 = plt.subplot(3, 2, 3)\n",
    "    for node_name, data in node_history.items():\n",
    "        ax3.plot(data['timestamps'], data['cpu'], \n",
    "                linewidth=2, marker='o', markersize=2, label=node_name, alpha=0.8)\n",
    "    ax3.set_ylabel('CPU Cores', fontsize=11, fontweight='bold')\n",
    "    ax3.set_title('CPU Usage by Node', fontsize=12, fontweight='bold')\n",
    "    ax3.legend(loc='upper left', fontsize=9)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    plt.setp(ax3.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    # 4. Per-Node Memory Usage\n",
    "    ax4 = plt.subplot(3, 2, 4)\n",
    "    for node_name, data in node_history.items():\n",
    "        ax4.plot(data['timestamps'], data['memory'], \n",
    "                linewidth=2, marker='o', markersize=2, label=node_name, alpha=0.8)\n",
    "    ax4.set_ylabel('Memory (GB)', fontsize=11, fontweight='bold')\n",
    "    ax4.set_title('Memory Usage by Node', fontsize=12, fontweight='bold')\n",
    "    ax4.legend(loc='upper left', fontsize=9)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    plt.setp(ax4.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    # 5. Top Namespace CPU Usage\n",
    "    ax5 = plt.subplot(3, 2, 5)\n",
    "    # Show top 5 namespaces by average CPU\n",
    "    ns_avg_cpu = {ns: sum(data['cpu'])/len(data['cpu']) \n",
    "                  for ns, data in pod_history.items() if data['cpu']}\n",
    "    top_ns = sorted(ns_avg_cpu.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    \n",
    "    for ns, _ in top_ns:\n",
    "        data = pod_history[ns]\n",
    "        ax5.plot(data['timestamps'], data['cpu'], \n",
    "                linewidth=2, marker='o', markersize=2, label=ns, alpha=0.8)\n",
    "    ax5.set_xlabel('Time', fontsize=11, fontweight='bold')\n",
    "    ax5.set_ylabel('CPU Cores', fontsize=11, fontweight='bold')\n",
    "    ax5.set_title('Top 5 Namespaces by CPU', fontsize=12, fontweight='bold')\n",
    "    ax5.legend(loc='upper left', fontsize=9)\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    ax5.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    plt.setp(ax5.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    # 6. Pod Count Over Time\n",
    "    ax6 = plt.subplot(3, 2, 6)\n",
    "    ax6.plot(cluster_totals['timestamps'], cluster_totals['pod_count'], \n",
    "             linewidth=2, color='#F18F01', marker='o', markersize=3)\n",
    "    ax6.fill_between(cluster_totals['timestamps'], cluster_totals['pod_count'], \n",
    "                      alpha=0.3, color='#F18F01')\n",
    "    ax6.set_xlabel('Time', fontsize=11, fontweight='bold')\n",
    "    ax6.set_ylabel('Pod Count', fontsize=11, fontweight='bold')\n",
    "    ax6.set_title('Active Pods Over Time', fontsize=12, fontweight='bold')\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    ax6.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    plt.setp(ax6.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_FILE, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n✅ Graphs saved to: {OUTPUT_FILE}\")\n",
    "    plt.close()\n",
    "\n",
    "def print_header():\n",
    "    \"\"\"Print the monitoring header\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"KUBERNETES CLUSTER MONITOR - JUPYTERHUB STRESS TEST\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Refresh interval: {REFRESH_INTERVAL} seconds\")\n",
    "    print(f\"Monitoring namespace: {'ALL' if SHOW_ALL_NAMESPACES else NAMESPACE}\")\n",
    "    print(f\"Graph output: {OUTPUT_FILE}\")\n",
    "    print(\"Press Ctrl+C to stop monitoring and generate graphs\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "def print_nodes(nodes):\n",
    "    \"\"\"Print node metrics in a formatted table\"\"\"\n",
    "    if not nodes:\n",
    "        print(\"⚠ No node metrics available. Is metrics-server installed?\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n📊 NODE METRICS\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'NODE':<30} {'CPU (cores)':<15} {'CPU %':<10} {'MEMORY (GB)':<15} {'MEM %':<10}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for node in nodes:\n",
    "        print(f\"{node['name']:<30} {node['cpu_cores']:<15.2f} {node['cpu_percent']:<10} \"\n",
    "              f\"{node['memory_gb']:<15.2f} {node['memory_percent']:<10}\")\n",
    "    \n",
    "    # Print totals\n",
    "    total_cpu = sum(n['cpu_cores'] for n in nodes)\n",
    "    total_mem = sum(n['memory_gb'] for n in nodes)\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'TOTAL':<30} {total_cpu:<15.2f} {'':<10} {total_mem:<15.2f}\")\n",
    "\n",
    "def print_pods(pods, top_n=10):\n",
    "    \"\"\"Print top N pods by resource usage\"\"\"\n",
    "    if not pods:\n",
    "        print(\"\\n⚠ No pod metrics available\")\n",
    "        return\n",
    "    \n",
    "    # Sort by CPU usage\n",
    "    pods_by_cpu = sorted(pods, key=lambda x: x['cpu_cores'], reverse=True)[:top_n]\n",
    "    \n",
    "    print(f\"\\n🔥 TOP {top_n} PODS BY CPU\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'NAMESPACE':<20} {'POD NAME':<35} {'CPU (cores)':<15} {'MEMORY (GB)':<15}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for pod in pods_by_cpu:\n",
    "        print(f\"{pod['namespace']:<20} {pod['name'][:34]:<35} \"\n",
    "              f\"{pod['cpu_cores']:<15.3f} {pod['memory_gb']:<15.2f}\")\n",
    "\n",
    "def check_metrics_server():\n",
    "    \"\"\"Check if metrics-server is installed\"\"\"\n",
    "    result = run_kubectl(\"kubectl get deployment metrics-server -n kube-system\")\n",
    "    if result is None:\n",
    "        print(\"\\n⚠️  WARNING: metrics-server not found!\")\n",
    "        print(\"To install metrics-server, run:\")\n",
    "        print(\"kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml\")\n",
    "        print(\"\\nFor Minikube/local clusters, you may need to enable it:\")\n",
    "        print(\"minikube addons enable metrics-server\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main monitoring loop\"\"\"\n",
    "    print_header()\n",
    "    \n",
    "    # Check for metrics-server\n",
    "    if not check_metrics_server():\n",
    "        print(\"\\nExiting...\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    print(\"Waiting for metrics to be available...\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    try:\n",
    "        iteration = 0\n",
    "        while True:\n",
    "            iteration += 1\n",
    "            timestamp = datetime.now()\n",
    "            \n",
    "            # Clear screen (optional - comment out if you want to keep history)\n",
    "            print(\"\\033[2J\\033[H\")  # ANSI escape codes to clear screen\n",
    "            \n",
    "            print"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
